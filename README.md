# comp_d2v_tpmodel
Doc2VecとTopicModelによるクラスタリング結果を比較するために作成したプログラミングです。  
４人の作家の文学作品を用意し、それぞれでクラスタリングを行い作家毎にクラスタリングされているかを比較しました。 
カウントベースと推論ベースで純文学を処理させた場合にどう違いがでるか調べています。  
（Doc2Vecでベクトル化しKmeansでクラスタリングしたものと、TopicModelでトピックわけした結果を比較しています。）

## クラスタリング対象データ  
- 梶井基次郎　４５作品  
- 永井荷風　　８５作品  
- 中島敦　　　２７作品  
- 夏目漱石　　１０４作品  

## 結果  
![kekka](https://user-images.githubusercontent.com/61402011/76580630-f6f11480-6513-11ea-92b1-ade1c3784038.png)  
作品数の少ない梶井基次郎と中島敦の作品は、どちらもうまくわけられていませんでした。  
一方で、作品数が多い永井荷風と夏目漱石の作品は、Doc2Vecではいい具合にわけられていました。  
単語の生起確率を求めるモデルよりも、単語の発生を推論するモデルの方が文学上の言い回しとかうまく処理できるとかあるのでしょうか？まだまだ理解が及びません。  

## プログラム上の問題点  
- TopicModelでもDoc2Vecでも、パラメータの調整をしっかりおこなっておりません。ですので、特にトピックモデルのno_belowやno_aboveなどを適切に調整できたらもっと良い結果がでるかもしれません。  
- kmeansは各クラスタの大きさが同じサイズでまとまっていくらしいので、今回のようにそれぞれのクラスタサイズが異なるケースでは、別のクラスタリング手法を用いたら、もっと良い結果が出たかもしれません。  

## 環境  
- 小説スクレイピング： ubuntu 18.04.4 / python 3.7.6  
- D2V,TopicModel：Google Colaboratory  

## ファイル内容  
- get_novel ディレクトリ：小説スクレイピング用にscrapyを利用しました。scrapy関連ファイルが入っています。 抽出した小説をpandasDataFrameに入れてpickleで保存しています。 
- Doc2Vec.ipynb：Google Colabで作成した、D2Vモデル作成に関するjupyter notebookファイルです。  
- topic_model.ipynb：Google Colabで作成した、topicmodel作成に関するjupyter notebookファイルです。



